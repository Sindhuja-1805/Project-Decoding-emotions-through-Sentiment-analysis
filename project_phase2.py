# -*- coding: utf-8 -*-
"""Project_phase2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GtAWyMg-XptMqu1JUK4iGpDEBIO4Zd9N

Upload the Dataset
"""

from google.colab import files
uploaded = files.upload()

""" Load the Dataset

"""

import pandas as pd

# Sample data (manually defined)
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Display the data
print(df)

"""Data Exploration

"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Sample social media emotion dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Display first few rows
print("Dataset Preview:\n", df.head())

# Dataset shape
print("\nDataset Shape:", df.shape)

# Data types
print("\nData Types:\n", df.dtypes)

# Check for missing values
print("\nMissing Values:\n", df.isnull().sum())

# Emotion class distribution
print("\nEmotion Distribution:\n", df['emotion'].value_counts())

# Plotting emotion distribution
plt.figure(figsize=(8, 5))
sns.countplot(data=df, x='emotion', palette='Set2')
plt.title('Emotion Distribution in Social Media Posts')
plt.xlabel('Emotion')
plt.ylabel('Count')
plt.grid(True)
plt.tight_layout()
plt.show()

""" Check for Missing Values and Duplicates

"""

import pandas as pd

# Sample data (no CSV)
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Check for missing values
print("Missing Values:\n", df.isnull().sum())

# Check for duplicate rows
print("\nDuplicate rows:", df.duplicated().sum())

"""Visualize a Few Features

"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sample emotion-labeled social media data
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Add a new column for text length
df['text_length'] = df['text'].apply(len)

# Distribution of emotions
sns.countplot(x='emotion', data=df, palette='Set2')
plt.title('Distribution of Emotions')
plt.xlabel('Emotion')
plt.ylabel('Count')
plt.show()

# Relationship between text length and emotion
sns.boxplot(x='emotion', y='text_length', data=df, palette='Set3')
plt.title('Text Length vs Emotion')
plt.xlabel('Emotion')
plt.ylabel('Text Length (characters)')
plt.show()

"""Identify Target and Features

"""

import pandas as pd

# Sample dataset for sentiment/emotion analysis
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Identify features and target
X = df['text']        # Features (input)
y = df['emotion']     # Target (output label)

# Print the results
print("Features (X):")
print(X.head())

print("\nTarget (y):")
print(y.head())

""" Convert Categorical Columns to Numerical

"""

import pandas as pd

# Sample dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Convert 'emotion' (categorical) to numerical using Label Encoding
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
df['emotion_encoded'] = label_encoder.fit_transform(df['emotion'])

# Display the updated DataFrame
print(df[['text', 'emotion', 'emotion_encoded']])

""" One-Hot Encoding

"""

import pandas as pd

# Sample dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# One-Hot Encode the 'emotion' column
emotion_one_hot = pd.get_dummies(df['emotion'])

# Concatenate the original dataframe with the new one-hot encoded columns
df_encoded = pd.concat([df, emotion_one_hot], axis=1)

# Display the resulting DataFrame
print(df_encoded)

""" Feature Scaling

"""

import pandas as pd
from sklearn.preprocessing import StandardScaler

# Sample dataset with emotion and text length
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Add a new column for text length
df['text_length'] = df['text'].apply(len)

# Initialize StandardScaler
scaler = StandardScaler()

# Scale the 'text_length' feature (numerical)
df['scaled_text_length'] = scaler.fit_transform(df[['text_length']])

# Display the resulting DataFrame with scaled text length
print(df[['text', 'emotion', 'text_length', 'scaled_text_length']])

""" Train-Test Split"""

import pandas as pd
from sklearn.model_selection import train_test_split

# Sample dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Features and Target
X = df['text']        # Features (input)
y = df['emotion']     # Target (output label)

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Display the results
print("Training Features (X_train):")
print(X_train)
print("\nTest Features (X_test):")
print(X_test)
print("\nTraining Target (y_train):")
print(y_train)
print("\nTest Target (y_test):")
print(y_test)

""" Model Building

"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Sample dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Features and Target
X = df['text']        # Features (input)
y = df['emotion']     # Target (output label)

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english', max_features=500)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Initialize the Logistic Regression model
model = LogisticRegression()

# Train the model
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

""" Evaluation"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Sample dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Features and Target
X = df['text']        # Features (input)
y = df['emotion']     # Target (output label)

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english', max_features=500)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Initialize the Logistic Regression model
model = LogisticRegression(max_iter=200)

# Train the model
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Detailed classification report (Precision, Recall, F1-Score)
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)

# Display Confusion Matrix using Seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

"""Make Predictions from New Input

"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Sample dataset
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Create DataFrame
df = pd.DataFrame(data)

# Features and Target
X = df['text']        # Features (input)
y = df['emotion']     # Target (output label)

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF
vectorizer = TfidfVectorizer(stop_words='english', max_features=500)
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Initialize the Logistic Regression model
model = LogisticRegression(max_iter=200)

# Train the model
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Confusion Matrix using Seaborn heatmap
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# -----------------------------------------------
# Making Predictions on New Input Text
# -----------------------------------------------

# Example of new input texts
new_texts = [
    "I’m feeling so happy right now!",
    "I can’t handle this anymore, I’m so angry!",
    "I miss my friends so much.",
    "I feel very nervous about the upcoming event.",
    "This is such a wonderful experience!"
]

# Preprocess the new input texts
new_texts_tfidf = vectorizer.transform(new_texts)

# Make predictions on new input texts
predictions = model.predict(new_texts_tfidf)

# Print out the predictions for the new texts
for text, emotion in zip(new_texts, predictions):
    print(f"Text: {text}\nPredicted Emotion: {emotion}\n")

""" Convert to DataFrame and Encode

"""

import pandas as pd
from sklearn.preprocessing import LabelEncoder

# Sample dataset (you can replace this with your actual data)
data = [
    {"text": "I'm feeling great today!", "emotion": "joy"},
    {"text": "This is so frustrating and annoying.", "emotion": "anger"},
    {"text": "I miss you so much.", "emotion": "sadness"},
    {"text": "I’m scared about the future.", "emotion": "fear"},
    {"text": "What a wonderful surprise!", "emotion": "surprise"},
    {"text": "I’m so proud of myself!", "emotion": "joy"},
    {"text": "Everything is going wrong!", "emotion": "anger"},
    {"text": "I just want to cry.", "emotion": "sadness"},
    {"text": "That really shocked me!", "emotion": "surprise"},
    {"text": "I feel anxious and nervous.", "emotion": "fear"}
]

# Convert the data into a DataFrame
df = pd.DataFrame(data)

# Check the DataFrame
print("Original DataFrame:")
print(df)

# --------------------------------------------
# 1. Label Encoding (for a single column)
# --------------------------------------------
label_encoder = LabelEncoder()

# Encode the 'emotion' column (target)
df['emotion_encoded'] = label_encoder.fit_transform(df['emotion'])

# Show the DataFrame after label encoding
print("\nDataFrame with Label Encoding:")
print(df)

# --------------------------------------------
# 2. One-Hot Encoding (for the 'emotion' column)
# --------------------------------------------
# Perform one-hot encoding for the 'emotion' column
df_one_hot = pd.get_dummies(df, columns=['emotion'], prefix=['emotion'])

# Show the DataFrame after one-hot encoding
print("\nDataFrame with One-Hot Encoding:")
print(df_one_hot)

""" Predict the Final Grade"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Sample data (replace this with your actual dataset)
data = [
    {"studytime": 2, "failures": 0, "health": 3, "G3": 12},
    {"studytime": 3, "failures": 1, "health": 2, "G3": 14},
    {"studytime": 1, "failures": 0, "health": 1, "G3": 10},
    {"studytime": 4, "failures": 0, "health": 5, "G3": 16},
    {"studytime": 2, "failures": 2, "health": 3, "G3": 11},
    {"studytime": 3, "failures": 1, "health": 2, "G3": 15},
    {"studytime": 4, "failures": 0, "health": 4, "G3": 17},
    {"studytime": 1, "failures": 1, "health": 1, "G3": 9},
    {"studytime": 3, "failures": 0, "health": 3, "G3": 13},
    {"studytime": 2, "failures": 1, "health": 4, "G3": 12}
]

# Create DataFrame
df = pd.DataFrame(data)

# Features and Target
X = df[['studytime', 'failures', 'health']]  # Features
y = df['G3']  # Target (final grade)

# Split the dataset into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling (Standardize the features)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the Linear Regression model
model = LinearRegression()

# Train the model
model.fit(X_train_scaled, y_train)

# Make predictions
y_pred = model.predict(X_test_scaled)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print evaluation metrics
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

# Print predictions and actual values
print("\nPredictions vs Actual values:")
for pred, actual in zip(y_pred, y_test):
    print(f"Predicted: {pred:.2f}, Actual: {actual:.2f}")

""" Deployment-Building an Interactive App

"""

import numpy as np
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.preprocessing.text import Tokenizer

# ----- Simulated Trained Model -----
class FakeEmotionModel:
    def predict(self, x):
        # Returns dummy prediction values for 6 classes
        return np.array([[0.1, 0.2, 0.3, 0.1, 0.2, 0.1]])

# ----- Simulated Tokenizer -----
def create_fake_tokenizer():
    tokenizer = Tokenizer(num_words=1000)
    sample_texts = [
        "I am happy", "I am sad", "I am angry", "I am scared", "I am surprised", "I feel nothing"
    ]
    tokenizer.fit_on_texts(sample_texts)
    return tokenizer

# Load model and tokenizer
model = FakeEmotionModel()
tokenizer = create_fake_tokenizer()

# Emotion labels
class_labels = ['Angry', 'Happy', 'Sad', 'Fear', 'Surprise', 'Neutral']

# --------- Main Program ---------
print("🎭 Emotion Detection App")
print("Type 'exit' to quit.")
while True:
    text = input("\nEnter a social media message: ")
    if text.lower().strip() == "exit":
        print("Goodbye!")
        break

    if not text.strip():
        print("⚠️ Please enter some valid text.")
        continue

    # Preprocessing
    sequence = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(sequence, maxlen=10)

    # Prediction
    prediction = model.predict(padded)
    predicted_label = class_labels[np.argmax(prediction)]

    # Output
    print(f"\n✅ Predicted Emotion: {predicted_label}")
    print("🔬 Confidence Scores:")
    for label, score in zip(class_labels, prediction[0]):
        print(f"   {label}: {score:.2%}")